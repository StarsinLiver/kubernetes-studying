<!-- 쿠버네티스 객체와 컨테이너 모니터링하기 -->
# 프로메테우스는 서비스 디스커버리를 통해 쿠버네티스와 통합되어 있다.
# 그리고 쿠버네티스 객체와 컨테이너의 상태 정보는 쿠버네티스 API를 통해 직접 수집할 수 없다.
# 이들 정보를 수집하려면 두 가지 별도의 컴포넌트가 필요하다.

# 하나는 구글에서 만든 cAdvisor 이고, 다른 하나는 깃허브의 쿠버네티스 조직 계정에서 관리하는 kube-state-metrics다.

# 두가지 도구 모두 클러스터에서 컨테이너 형태로 동작하지만, 데이터를 수집하는 채널이 서로 다르다.
# cAdivisor는 컨테이너 런타임에서 정보를 수집한다. 따라서 데몬셋 형태로 노드마다 하나씩 배치되어 해당 노드에 있는 컨테이너의 상태 정보를 수집한다.
# 반면 kube-state-metrics는 쿠버네티스 API를 통해 측정값을 수집하므로 아무 노드에나 단일 레플리카 디플로이먼트로 실행된다.

<!-- 실습 -->
# cAdvisor와 kube-state-metrics의 측정값 수집기를 배치하라. 그리고 이들에서 측정값을 스크래핑하게끔 프로메테우스 설정을 변경하라.

# cAdvisor와 kube-state-metrics를 배치한다
kubectl apply -f kube/

# cAdvisor가 준비될 때까지 대기한다
kubectl wait --for=condition=ContainersReady pod -l app=cadvisor -n kube-system

# 프로메테우스 설정을 변경한다
kubectl apply -f prometheus/update/prometheus-config-kube.yaml

# 변경된 컨피그맵이 파드에 적용될 때까지 대기한다
sleep 30

# 프로메테우스가 변경된 설정을 적용하도록 HTTP POST 요청을 보낸다
# 프로메테우스는 재시작없이도 설정을 변경할 수 있지만, 컨피그맵이 변경되었다는 것을 알려주어야 한다.
curl -X POST $(kubectl get svc prometheus -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:9090/-/reload' -n kiamol-ch14-monitoring)

# 위의 (윈도우라면)
Invoke-RestMethod -Method Post -Uri (kubectl get svc prometheus -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:9090/-/reload' -n kiamol-ch14-monitoring)

# 프로메테우스 UI를 보면 /graph 페이지에서
# 컨테이너와 쿠버네티스 객체에 대한 측정값이 추가됐다

# 이번 실습 예제를 실행하고 나면 프로메테우스가 수집하는 측정값이 엄청나게 늘어낫을 것이다.
# 각 컨테이너가 소모하는 계산 자원부터 각 파드 상태까지 많은 정보가 추가된다. 그리고 프로메테우스의 /targets 페이지를 보면 새롭게 추가된 스크래핑 대상에 항목이 있을 거싱다.
# 프로메테우스는 변경된 설정을 자동으로 적용하는 기능이 없으므로 변경된 컨피그맵이 파드에 적용되는 것을 기다려 수동으로 curl 명령을 사용하여 프로메테우스가 설정을 다시 읽어 들이도록 했다.

# 새로 변경된 프로메테우스 설정에는 잡 정의 두 개가 추가되었다. 이 정의를 보면 kube-state-metrics는 서비스의 전체 도메인 네임이 기재된 정적 스크래핑 대상으로 지정되었다. 파드 하나가 모든 측정값을 수집하므로 로드밸런싱은 신경 쓸 필요가 없다.
# 반면 cAdvisor는 쿠버네티스 서비스 디스커버리 기능을 사용하여 데몬셋에 포하모딘 모든 파드를 찾아낸다. 따라서 다중 노드 클러스터에서도 각 노드마다 하나의 대상이 생긴다

<!-- Prometheus-config-kube.yaml : 프로메테우스의 신규 스크래핑 대상 정의 -->
...
    scrape_configs:
...   
      - job_name: 'cadvisor'                                         # 컨테이너의 측정값 스크래핑 대상은
        kubernetes_sd_configs:                                       # 쿠버네티스 서비스 디스커버리 기능을 사용하여 지정
        - role: pod                                                  # 네임스페이스와 레이블이 일치하는 
        relabel_configs:                                             # 모든 데몬셋의 파드를 대상으로 함
        - source_labels:  
            - __meta_kubernetes_namespace
            - __meta_kubernetes_pod_labelpresent_app
            - __meta_kubernetes_pod_label_app
          action: keep
          regex: kube-system;true;cadvisor

      - job_name: 'kube-state-metrics'                                # 쿠버네티스 객체 측정값의 스크래핑 대상은 
        static_configs:                                               # 도메인 네임을 값으로 정적 스크래핑 대상을 지정
        - targets:
            - kube-state-metrics.kube-system.svc.cluster.local:8080 
            - kube-state-metrics.kube-system.svc.cluster.local:8081

# 이제 무작위 숫자 애플리케이션의 대시보드와는 정반대인 문제가 생겼다. 새로운 측정값이 너무 많아 플랫폼 대시보드는 유용한 정보 외에는 대부분의 측정값을 쳐내야 한다.
# 이 대시보드에는 현재 자원 사용량과 클러스터에 남은 가용 자원량, 네임스페이스별로 분류된 노드의 정상 여부 현황 등이 있다.

<!-- 실습 2 -->
# 클러스터 관련 핵심 특정값을 골라 담은 대시보드 정의를 배치한 후 그라파나에서 이 정의를 불러들여라

# 대시보드 정의가 담긴 컨피그맵을 배치하고
# 그라파나에 변경을 적용한다
kubectl apply -f grafana/update/kube/

# 그라파나가 다시 준비될 때까지 대기한다
kubectl wait --for=condition=ContainersReady pod -l app=grafana -n kiamol-ch14-monitoring

# 새로 추가된 대시보드의 URL을 확인한다
kubectl get svc grafana -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:3000/d/oWe9aYxmk' -n kiamol-ch14-monitoring

# 대시보드를 확인한다

# 이 대시보드는 플랫폼 대시보드 중에서 저수준 정보로 구성된 것이다.
# 이 대시보드로는 클러스터에 잔여 리소스가 얼마나 남았는지 정도밖에는 알 수 없다. 이 그래프를 그리는 데 쓰인 질의는 오히려 클러스터 리소스가 얼마 남지 않은 상황을 경고하는 목적에 적합하다.
# 쿠버네티스에도 리소스 잔량이 적을 때 경고해주는 기능이 있다.
# 대시보드에서 메모리 잔량과 CPU 자원 잔량, 리스크 용량 잔량을 볼 수 있는데, 이런 자원이 부족하면 파드 컨테이너가 강제 종료될 수 있기 때문에 이들 값을 주의해서 살펴야 한다.

<!-- 애플리케이션 대시보드에 참고 정보로 추가하는 방법 -->
# 플랫폼 측정값을 이용하는 또 다른 방법이 있다. 애플리케이션 자체에서 충분히 자세한 측정값을 얻을 수 없을 때 애플리케이션 대시보드에 참고 정보로 추가하는 방법이다.
# 조금 전 플랫폼 대시보드에서는 전체 클러스터의 계산 자원 사용량 합계를 보여 주었지만, 실제 집계는 컨테이너 단위로 한다. 따라서 애플리케이션과 관련된 특정 부하만 골라낸 플랫폼 측정값을 애플리케이션 대시보드에 추가할 수 있다.

<!-- 실습 3 -->
# 무작위 숫자 API의 대시보드에 플랫폼 측정값을 추가하라. 그라파나의 설정만 변경하고 애플리케이션 자체나 프로메테우스의 설정은 건드리지 않아도 된다.

# 대시보드 정의를 변경한다
kubectl apply -f grafana/update/grafana-dashboard-numbers-api-v2.yaml

# 그라파나를 재시작해 변경된 대시보드를 적용한다
kubectl rollout restart deploy grafana -n kiamol-ch14-monitoring

# 파드가 재시작할 때까지 대기한다
kubectl wait --for=condition=ContainersReady pod -l app=grafana -n kiamol-ch14-monitoring

# 무작위 숫자 API의 대시보드를 확인한다

# 지금까지의 주요 부분 중 지금까지 다루지 않은 것은 서버 단위의 측정값 수집과 이상 상태를 알려주는 경보 설정이다. 서버 단위의 측정값으로는 디스크나 네트워크 사용량 등이 있다.
# 이런 정보는 노드용 추출기를 사용하여 노드에서 직접 수집하도록 하고(노드용 추출기는 윈도우 서버 버전과 리눅스 서버 버전 모두 있음), 서비스 디스커버리 기능을 사용하여 노드를 스크래핑 대상에 추가한다.
# 프로메테우스는 PromQL 질의 언어를 사용하여 규칙을 정의할 수 있는 복잡한 경보 시스템도 갖추고 있다.
# 규칙에 따라 경보를 발동하도록 설정하면 이메일,슬랙 메시지, 페이저듀티등 수단을 이용하여 프로메테우스에서 경보를 받을 수 있다.

