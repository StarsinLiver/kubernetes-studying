<!-- 수집된 로그를 엘라스틱서치에 저장하기 -->
# 엘라스틱서치(Elastic search)는 이미 산업에서 널리 쓰이는 오픈 소스 데이터베이스다.
# 엘라스틱 서치는 도큐먼트(Document) 단위로 데이터를 저장하며, 이 도큐먼트가 모인것을 인덱스(Index)라고 한다.
# 또한 한 인덱스 안에서도 도큐먼트가 고정된 스키마를 갖지 않는다는 점에서 엘라스틱서치는 우리에게 익숙한 관계형 데이터베이스와 사뭇 다른 데이터 저장 모델을 갖는다.

# 엘리스틱서치에 저장된 도큐먼트는 제각각 다른 필드로 구성될 수 있다.
# 이런 특성 덕분에 여러 시스템에서 생성한 서로 다른 내용을 가진 로그를 한곳에 수집할 수 있고, 이점이 중앙화된 로그 시스템에 매우 적합하다.
# 엘라스틱서치는 데이터를 저장하고 조회하는 용도로 쓰이는 REST API를 가진 단일 컴포넌트 형태로 실행된다.

# 엘라스틱서치와 영혼의 단짝인 키바나가 엘라스틱서치에서 데이터를 조회하기 위한 프론트엔드 역할을 한다.
# 이 두 컴포넌트를 플루언트비트를 실행했던 네임스페이스에서 함께 실행해 보자

<!-- 실습 -->
# 로그 저장소와 그 프론트엔드인 엘라스틱서치와 키바나를 배치하라

# 일래스틱서치 디플로이먼트를 생성하고 파드가 준비될 때까지 대기
kubectl apply -f elasticsearch/

kubectl wait --for=condition=ContainersReady pod -l app=elasticsearch -n kiamol-ch13-logging

# 키바나 디플로이먼트를 생성하고 파드가 준비될 때까지 대기
kubectl apply -f kibana/

kubectl wait --for=condition=ContainersReady pod -l app=kibana -n kiamol-ch13-logging

# 키바나에 접근할 수 있는 URL 확인
kubectl get svc kibana -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:5601' -n kiamol-ch13-logging

# 엘라스틱서치와 키바나의 디플로이먼트는 기본적으로 각각 파드 하나로 구성된다. 로그의 중요성을 생각하면 운영 환경에서는 로그 시스템에 고가용성을 확보하고 싶을 수도 있다.
# 키바나는 무상태 컴포넌트이므로 레플리카 수를 늘리기만 하면 고가용성을 확보할 수 있다.
# 엘라스틱서치는 스토리지를 공유하며 여러개의 파드에 걸쳐 동작하는 스테이트풀셋 형태로 실행되지만, 클라우드에서 실행되는 매니지드 서비스 형태로 사용해도 좋다.
# 키바나를 실행했다면 키바나의 URL로 접근하자

# 플루언트 비트는 엘라스틱서치를 출력 대상으로 하는 플러그인을 지원한다. 이 플러그인은 로그 앤트리 하나하나를 엘라스틱서치 REST API를 통해 도큐먼트로 저장한다.
# 플로그인의 필수 설정은 엘라스틱 서치 서버의 도메인 네임뿐이며, 여기에 부가적으로 도큐먼트가 저장될 인덱스를 지정할 수도 있다.
# 다중 출력 대상을 가진 출력 단계와 이런 설정을 조합하면 서로 다른 네임스페이스에서 발생한 로그를 제각기 다른 인덱스에 지정할 수 있다.
# 다중 출력 대상을 가진 ㅜㄹ력 단계와 이런 설정을 조합하면 서로 다른 네임스페이스에서 발생한 로그를 제각기 다른 인덱스에 저장할 수 있다.

<!-- fluentbit-config-elasticsearch.yaml : 엘라스틱서치 인덱스에 로그를 저장 -->
...
  output.conf: |
    [OUTPUT]
        Name            es                          # 테스트 네임스페이스의 로그를
        Match           kube.kiamol-ch13-test.*     # 엘라스틱서치에 저장하되
        Host            elasticsearch               # 로그를 저장하는 인덱스를
        Index           test                        # 'test'로 지정한다.
        Generate_ID     On

    [OUTPUT]
        Name            es                          # 쿠버네티스 시스템 파드이 로그는
        Match           kube.kube-system.*          # 동일한 엘라스틱서치 서버의  
        Host            elasticsearch               # 'sys' 인덱스에 저장한다.
        Index           sys
        Generate_ID     On
...

# 어떤 출력 규칙과도 일치하지 않는 로그는 폐기된다.
# 따라서 이 같은 설정을 적용하면 쿠버네티스 시스템 로그와 테스트 네임 스페이스의 로그는 엘라스틱서치에 저장되지만 개발 네임스페이스의 로그는 저장되지 않는다.

<!-- 실습 2 -->
# 엘라스틱서치에 로그를 저장하도록 플루언트 비트의 설정을 변경하라. 그리고 키바나 웹 UI를 통해 test 인덱스 조회를 설정하라

# 위의 설정 적용
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl apply -f .\fluentbit\update\fluentbit-config-elasticsearch.yaml
configmap/fluent-bit-config configured

# 플루언트 비트 파드를 재시작한후 대기
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl rollout restart ds/fluent-bit -n kiamol-ch13-logging
daemonset.apps/fluent-bit restarted

# 파드가 준비상태까지 기다림
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl wait --for=condition=Ready pod -l app=fluent-bit -n kiamol-ch13-logging
pod/fluent-bit-vdjd2 condition met

# 이제 키바나 웹 UI를 통해 데이터 조회를 설정
# - 좌측 메뉴에서 Discover를 클릭
# - Create index pattern 버튼을 클릭
# - Index pattern 입력 칸에 'test'를 입력
# - Next step 버튼을 클릭후
# - Time Filter field name 입력칸에서 @timestamp를 선택
# - Create Index Pattern 버튼을 클릭
# - 다시한번 왼쪽 메뉴에서 Discover를 클릭하여 로그를 관찰

# 키바나가 완전히 자동화가 되어 있지는 않기 때문에 이번 실습 예제에서 직접 UI를 통한 몇가지 조작이 필요했다.
# Discover 탭을 보면 단위 시간당 저장되는 도큐먼트 수를 확인할 수 있다.
# 이 수치가 바로 단위 시간당 처리되는 로그 수다.
# 바로 도큐먼트 하나하나에 접근하여 로그의 세부 내용을 살필 수 있다.

<!-- 키바나 UI -->
# 엘라스틱서치와 키바나는 이미 널리 쓰이는 기술이지만 여러분이 이들을 다루는데 익숙치 않으니 키바나 ui를 가볍게 훑어보도록 하자.
# Discover 페이지의 왼편을 보면 로그를 필터링하는 기준으로 삼을 수 있는 필드 목록이 있다.
# 이 목록에는 모든 쿠버네티스 메타데이터 필드가 포함되어 있기때문에 파드 이름, 호스트 노드, 커넽이너 이미지등을 기준으로 로그를 필터링할 수 있다.
# 또한 애플리케이션별로 주요 통계를 항상 보여 주는 대시보드도 구성할 수 있다.
# 이들 대시보드는 오류 로그가 급증하는 이상현상을 쉽게 발견하게 해 준다.
# 그런가 하면 모든 도큐먼트 중 특정한 원하는 값이 포함한 것이 있는지 찾아볼 수 있다.
# 이런 방식은 로그에서 사용자 제보로 들어온 오류 메시지 식별자를 검색할 때 유용하다.

<!-- 중앙화된 로그 시스템의 장점 -->
# 테스트 네임스페이스에 새로운 애플리케이션을 하나 배치한다. 플루언트 비트의 설정을 수정하지 않아도 이 애플리케이션의 로그는 그대로 수집되어 엘라스틱서치에 저장된다. 그리고 사용중 오류가 발생하면 이 오류와 관련된 정보를 키바나를 통해 어렵지 않게 추척할 수 있다.

<!-- 실습 3 -->
# 이 애플리케이션은 두번째 호출부터 오류를 일으키게 만들어 졌지만 프록시를 함께 배치하면 프록시가 응답을 캐싱해 주기 때문에 거의 문제를 일으키지 않는다.
# API를 호출해보고 오류가 발생하면 키바나에서 오류 식별자를 검색하라

# API와 프록시를 배치한다
kubectl apply -f numbers/

# 애플리케이션이 시작될 때까지 대기한다
kubectl wait --for=condition=ContainersReady pod -l app=numbers-api -n kiamol-ch13-test

# 프록시를 경유해 API에 접근하는 URL을 확인한다
kubectl get svc numbers-api-proxy -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8080/rng' -n kiamol-ch13-test

# API를 호출한 뒤 30초를 기다려 페이지를 새로고침하면 오류가 발생한다
# 키바나에서 검색창에 아래와 같은 질의를 입력하라
# kubernetes.labels.app:numbers-api AND log:<API에서_출력된_오류_식별자>

# 검색 가능한 중앙화된 로그 시스템은 문제를 매우 편리하게 해결할 수 있게 한다.
# 게빌환경과 테스트환경에서도 운영 환경과 동일한 진단 도구를 사용할 수 있다면 운영 팀에서도 로그 수준을 이해하고 시스템 로그를 좀 더 유용하게 개선할 수 있다.

