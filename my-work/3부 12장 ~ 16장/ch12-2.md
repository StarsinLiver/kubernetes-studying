<!-- 고장을 일으킨 파드 재시작하기 : 리브니스 프로브 -->
# 리브니스 프로브의 상태 체크 매커니즘은 레디니스 프로브와 동일하다.
# 하지만 고장을 일으킨 파드에 대한 조치는 레디니스 프로브와 다르다.

# 리브니스 프로브의 조치는 컴퓨팅 수준이라고 할 수 있는 파드 재시작이다.
# 여기에서 말하는 재시작은 파드 컨테이너의 재시작이다. 파드 자체는 원래 있던 노드에 그대로 남는다.

# 밑의 무작위 숫자 API정의에 포함된 리브니스 프로브의 설정이다.
# 여기에서도 HTTP GET 요청을 통해 상태를 체크하지만, 몇가지 추가된 설정잉 있다.
# 파드 재시작은 엔드포인트 목록에서 제외하는 것 보다는 훨씬 적극적인 조치다. 그런만큼 이 조치를 취할 시점을 더 명확히 하는 추가적인 설정이 잇다.

<!-- # api.with0readiness-and-liveness.yaml -->
apiVersion: apps/v1
kind: Deployment
metadata:
  name: numbers-api
  labels:
    kiamol: ch12
spec:
  replicas: 2
  selector:
    matchLabels:
      app: numbers-api
  template:
    metadata:
      labels:
        app: numbers-api
        version: v3
    spec:
      restartPolicy: Always
      containers:
        - name: api
          image: kiamol/ch03-numbers-api
          ports:
            - containerPort: 80
              name: api
          env:
            - name: FailAfterCallCount
              value: "1"
          readinessProbe:                 # < 레디니스 프로브 >
            httpGet:                      # HTTP GET 요청
              path: /healthz              # .../healthz 80번 포트로 
              port: 80
            periodSeconds: 5              # 5초간격으로 전송
          livenessProbe:                  # < 리브니스 프로브 >
            httpGet:                      # HTTP GET 요청을 통해 상태 체크
              path: /healthz              # .../healthz 80번 포트로 
              port: 80
            periodSeconds: 10             # 10초 간격으로 전송
            initialDelaySeconds: 10       # 첫번째 상태 체크 전 10초간 대기
            failureThreshold: 2           # 상태 체크 실패 두 번까지는 용인


# 리브니스 프로브 설정은 파드 정의이므로 이번 업데이트를 반영하면 새로운 대체 파드가 생성된다.
# 이번에도 파드가 고장을 일으키면 레디니스 프로브가 서비스에서 파드를 제외하여 그 다음에는 리브니스 프로브가 파드를 재시작해서 파드가 서비스에 복귀한다.

<!-- 실습 -->
# API컴포넌트를 업데이트하고, 리브니스 및 레디니스 프로브가 함께 동작하며 애플리케이션을 정상 상태로 유지하는지 확인하라

# 예제 12-2의 파드 정의를 반영
kubectl apply -f numbers/update/api-with-readiness-and-liveness.yaml

# 새로운 파드가 준비될 때까지 대기
kubectl wait --for=condition=ContainersReady pod -l app=numbers-api,version=v3

# 파드의 상태를 확인
kubectl get pods -l app=numbers-api -o wide

# 서비스 엔드포인트 목록을 확인
kubectl get endpoints numbers-api # 항목이 두 개

# 한쪽 파드에 고장을 일으킴
curl "$(cat api-url.txt)/rng"

# 프로브가 상태를 체크할 때까지 대기한 후
# 파드의 상태를 다시 확인
sleep 20
kubectl get pods -l app=numbers-api
NAME                           READY   STATUS    RESTARTS      AGE
numbers-api-7bf6c69dfb-2rt59   1/1     Running   1 (60s ago)   100s
numbers-api-7bf6c69dfb-bswtl   1/1     Running   0             104s

# 이번 실습 예제에서 리브니스 프로브가 고장을 일으킨 애플리케이션 파드를 재시작하는 것을 볼 수 있다.
# 재시작 대상은 파드 컨테이너이므로 IP 주소등 파드 환경은 그대로 유지된다.
# 컨테이너에 공디렉터리 볼륨이 마운트되어 있었다면, 교체된 컨테이너에서도 동일하게 파일에 접근할 수 있다.

# 애플리케이션이 정상 상태를 오래 유지하지 못하고 계속 고장을 일으킨다면 재시작 역시 완전한 해결책이 되지 못한다.
# 쿠버네티스가 파드를 재시작하는 횟수에도 한계가 있기 때문이다.
# 일시적인 문제라면 대체 컨테이너에서 애플리케이션이 정상을 회복한다.
# 프로브는 애플리케이션 업데이트 중에도 유용하다.

# 롤아웃은 새로 투입된 파드가 준비 상태가 되어야 다음 롤아웃을 진행하는데 이때 레디니스 프로브의 상태 체크가 실패하면 롤아웃이 진행되지 않는다.

# 이번 정의에는 웹 컴포넌트 프로브는 지금까지 마찬가지로 HTTP GET요청 액션을 사용하지만, 데이터베이스 컴포넌트에는 HTTP 엔드포인트가 없으므로 대신 TCP 소켓통신을 사용한다.
# 소켓 통신 액션은 지정된 포트가 열려있고 이 포트로 들어오는 트래픽을 주시하는지 확인한 후 컨테이너 안에서 지정된 명령을 실행하는 형태로 조치로 취한다.

<!-- todo-db.yaml : TCP 통신 및 명령 실행 프로브 -->
apiVersion: apps/v1
kind: Deployment
metadata:
  name: todo-db
  labels:
    kiamol: ch12
spec:
  selector:
    matchLabels:
      app: todo-db
  template:
    metadata:
      labels:
        app: todo-db
    spec:
      containers:
        - name: db
          image: postgres:11.6-alpine
          env:
          - name: POSTGRES_PASSWORD_FILE
            value: /secrets/postgres_password
          volumeMounts:
            - name: secret
              mountPath: "/secrets"
            - name: data
              mountPath: /var/lib/postgresql/data
          readinessProbe:
            tcpSocket:                # 레디니스 프로브는 
              port: 5432              # 데이터베이스가 이 포트를 주시하는지 체크
            periodSeconds: 5
          livenessProbe:              # 리브니스 프로브는 명령행 도구를 실행하여
            exec:                     # 데이터베이스가 동작중인지 체크
              command: ["pg_isready", "-h", "localhost"]
            periodSeconds: 10
            initialDelaySeconds: 10
      volumes:
        - name: secret
          secret:
            secretName: todo-db-secret
            defaultMode: 0400
            items:
            - key: POSTGRES_PASSWORD
              path: postgres_password
        - name: data
          emptyDir: {}

# 이 정의를 배치하면 애플리케이션 동작에는 변화가 없다 하지만 웹 컴포넌트와 데이터베이스 컴포넌트 모두 일시적인 오류에 대해 보호받을 수 있다.

<!-- 실습2 -->
# 자기수복형 애플리케이션으로 수정된 to-do 애플리케이션을 실행하라

# 웹 및 데이터베이스 컴포넌트를 배치
kubectl apply -f todo-list/db/ -f todo-list/web/

# 애플리케이션이 준비될 때까지 대기
kubectl wait --for=condition=ContainersReady pod -l app=todo-web

# 서비스의 URL을 확인
kubectl get svc todo-web -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8081'

# 애플리케이션에 접근해 새 항목을 추가

# 그림에서 보듯이 겉으로 보기에 달라진 것은 없다.
# 하지만 데이터베이스 컴포넌트의 프로브가 데이터베이스 서버가 준비될 때까지 트래픽이 전달되지 않게 하므로, 데이터베이스 서버가 고장을 일으키고 파드가 재시작되더라도 대체 파드가 동일한 공디렉터리 볼륨에 담긴 동일한 파일을 사용한다.

<!-- 업데이트 -->
# 업데이트 중 이상을 일으키더라도 프로브를 이용하여 애플리케이션의 정상 상태를 유지할 수 있다.
# todo 애플리케이션의 PostgreSQL 데이터베이스 버전이 업그레이드된 새로운 정의가 나왔다고 하자. 그런데 이 정의에 컨테이너 명령이 오버라이드되어 PostgreSQL 데이터베이스가 제대로 실행되지 않는다.
# 아마도 누군가가 애플리케이션을 실행하지 않고 파드만 실행하여 변경된 설정을 점검하려고 했다가 수정했던 코드를 그대로 남겨 둔 것 같다.
# "남아 있는 디버그 코드가 일으키는 버그(left over from debuggin mistake)"의 전형적인 형태이다.
# sleep 명령때문에 파드가 실행 상태로 남아 있지만 웹 컴포넌트에서 접속할 데이터베이스 서버가 없는 상황이 벌어진다.
# 프로브가 이 같은 사태를 막아 주고 애플리케이션을 정상 상태로 유지한다.

<!-- 실습 3 -->
# 오류가 있는 업데이트를 배치한 후 새로운 파드의 프로브 상태 체크가 실패하여 기존 파드가 그대로 남아 있는 것을 관찰하라.

# 업데이트를 반영
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> kubectl apply -f .\todo-list\db\update\todo-db-bad-command.yaml
deployment.apps/todo-db configured

# 파드 상태를 모니터링
# 리브니스 프로브의 상태 체크가 실패하여 파드가 재시작한다.
# 레디니스 프로브의 상태 체크 역시 계속 실패하여 파드가 준비 상태에 진입하지 못하고, 이것으로 기존 파드가 제거되지 못한다.
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> kubectl get pods -l app=todo-db --watch
NAME                       READY   STATUS    RESTARTS   AGE
todo-db-5d4994db89-nqnmx   0/1     Running   0          7s
todo-db-975596846-lxctx    1/1     Running   0          7m6s
todo-db-5d4994db89-nqnmx   0/1     Running   1 (0s ago)   60s
todo-db-5d4994db89-nqnmx   0/1     Running   2 (1s ago)   2m1s

# 새로 생성된 데이터베이스 파드가 준비 상태로 진입하지 못한다.
# 레디니스 프로브가 5342번 포트가 열려있지 않다고 확인했기 때문이다.
# 또 리브니스 프로브가 PostgreSQL 데이터베이스가 클라이언트 접속을 받을 수 있는 상태인지 확인하는 명령을 실행하는데, 이 역시 통과하지 못해 파드가 반복적으로 재시작한다.
# 새 파드가 준비 상태로 진입하지 못하니 기존 파드가 그대로 남아 있고 그 결과 애플리케이션이 정상적으로 동작한다.

# 5분쯤 후 다시 애플리케이션의 상태를 확인해 보면, 파드 상태가 크래시루프백오프(CrashloopBackOff) 상태에 빠진것을 볼 수 있다.
# 이 상태는 정상적으로 실행될 수 없는 파드를 계속 재시작하느라 클러스터 자원이 낭비되는 것을 막아주는 수단이다. 이 상태가 되면 파드가 재시작되는 시간 간격이 점차 늘어난다.
