<!-- 운영 환경으로 가자!! -->
<!-- 자기수복형 애플리케이션 활용하기 -->

# 쿠버네티스는 컴퓨팅 계층과 네트워킹 계층의 추상화로 애플리케이션을 모델링한다.

# 쿠버네티스가 네트워크 트래픽과 컨테이너 생애 주기를 통제할 수 있는 것도 이들 계층의 추상화 때문이며,

# 이런 통제력으로 애플리케이션 일부분이 고장을 일으키더라도 고장 난 부분을 수복할 수 있다.

# 애플리케이션 정의를 잘 작성한다면 클러스터 자체에서 애플리케이션의 일시적인 문제를 찾아 해결하는 것도 가능하다.

# 이런 애플리케이션을 자기수복형 애플리케이션이라고 하며, 일시적으로 발생하는 문제를 사람의 개입 없이도 해결할 수 있는것이 특징이다.

# 이 장은 컨테이너 프로브를 활용하여 애플리케이션 정상 여부를 확인하고, 애플리케이션이 리소스 부족에 빠지지 않도록 리소스 사용 한계를 설정하여 자기수복형 애플리케이션을 구성하는 방법을 다룬다.

# 쿠버네티스의 애플리케이션 수복 능력에는 한계가 있다. 이런 수복 능력의 한계가 어디까지인지 알아본다.

# 사람의 개입없이 애플리케이션이 계속 동작하게 하는 것이 주 목표이지만 애플리케이션 업데이트도 다시 살펴볼 것이다.

<!-- 정상 파드에만 트래픽 라우팅하기 : 레디니스 프로브 -->

# 쿠버네티스는 파드 컨테이너가 실행중인지 파악할 수 있지만, 컨테이너 속에 동작하는 애플리케이션 상태가 정상인지는 알 수 없다.

# 따라서 쿠버네티스에는 컨테이너 프로브(Container probe)를 통해 애플리케이션의 정상 상태 여부를 판단하는 기능이 있다.

# 도커 이미지에도 헬스체크 기능을 설정할 수 있지만, 쿠버네티스는 자신의 프로브를 우선하기 때문에 헬스체크 설정을 무시한다.

# 프로브는 파드 정의에 기술되며, 고정된 스케줄로 실행되어 애플리케이션의 특정한 측면을 시험하고 애플리케이션 상태가 현재 정상이라고 판단할 수 있는 지표를 반환한다.

# 프로브가 컨테이너 상태가 비정상이라고 응답한다면 쿠버네티스가 조치에 나선다. 다만 조치 내용은 프로브 유형에 따라 달라진다.

# 레디니스 프로브(readiness probe)는 네트워크 수준에서 조치되는데, 네트워크 요청을 처리하는 컴포넌트에 대한 라우팅을 관리하는 조치다.

# 파드 컨테이너의 상태가 비정상으로 판정되면 해당 파드는 준비 상태에서 제외되며, 서비스의 활성 파드 목록에서도 제외된다.

# 레디니스 프로브는 일시적인 과부하 문제를 해결하는데 적합하다.

# 일부 파드에 과부하가 걸려 모든 요청에 상태 코드 503을 반환하고 있다면, 레디니스 프로브의 확인 요청에도 정상을 의미하는 상태 코드 200이 아닌 상태 코드 503을 반환할 것이다.

# 따라서 이들 파드는 서비스에서 제외되어 더 이상 요청을 받지 않는다.

# 파드가 서비스에서 제외된 후에도 레디니스 프로브는 과부하 상태의 파드가 복귀할 기회를 주는데, 이때 상태 확인에서 정상으로 돌아오면 파드는 다시 서비스의 엔드포인트 목록에 복귀한다.

<!-- 실습 : 먼제 레디니스 프로브 없이 애플리케이션을 실행해보자 -->
# API를 두 개 이상의 레플리카로 실행하라. 그리고 컨테이너 프로브 없이 애플리케이션이 오류를 일으키면 어떤 현상이 발생하는지 관찰하라

# 무작위 숫자 생성 애플리케이션의 API
# 컴포넌트를 배치
kubectl apply -f numbers/

# API 컴포넌트가 준비될 때까지 대기
kubectl wait --for=condition=ContainersReady pod -l app=numbers-api

# 파드가 서비스의 엔드포인트 목록에 포함됐는지 확인
kubectl get endpoints numbers-api

# API의 URL을 텍스트 파일에 저장
kubectl get svc numbers-api -o jsonpath='http://{.status.loadBalancer.ingress[0].*}:8013' > api-url.txt

# API를 호출 -- 요청 응답 후, 애플리케이션이 오류를 일으킨다
curl "$(cat api-url.txt)/rng"

# 상태 확인용 엔드포인트로 API의 상태를 확인 -- 오류
curl "$(cat api-url.txt)/healthz"; curl "$(cat api-url.txt)/healthz"

# 서비스와 연결된 파드의 목록을 확인
# 두 파드가 아직 서비스의 엔드포인트 목록에 그대로 남아 있다.
kubectl get endpoints numbers-api
NAME          ENDPOINTS                   AGE
numbers-api   10.1.1.69:80,10.1.1.70:80   3m30s

# 이런 현상이 일어나는 이유는 파드가 고장을 일으킨 것을 쿠버네티스에서 알 수 없기 때문이다.
# 파드 컨테이너에는 애플리케이션이 실행 중인 상태고, 쿠버네티스 입장에서는 애플리케이션이 제대로 동작하는지 확인할 수 있는 상태 확인 엔드포인트가 있다는 것을 알 수 없다.
# 파드 정의에 레디니스 프로브를 추가하여 쿠버네티스가 상태 확인 엔드포인트를 사용하게 할 수 있다.

<!-- api-with-readiness.yaml -->
apiVersion: apps/v1
kind: Deployment
metadata:
  name: numbers-api
  labels:
    kiamol: ch12
spec:
  replicas: 2
  selector:
    matchLabels:
      app: numbers-api
  template:
    metadata:
      labels:
        app: numbers-api
        version: v2
    spec:
      restartPolicy: Always
      containers:
        - name: api
          image: kiamol/ch03-numbers-api
          ports:
            - containerPort: 80
              name: api
          env:
            - name: FailAfterCallCount
              value: "1"
          readinessProbe:                   # 프로브는 컨테이너 수준에서 정의된다.
            httpGet:
              path: /healthz                # 이 URL에 HTTP GET 요청을 보낸다.
              port: 80
            periodSeconds: 5                # 5초에 한번씩 상태를 확인한다.

# 쿠버네티스에는 여러 유형의 컨테이너 프로브가 있다. 여기 나온 컨테이너 프로브는 웹 애플리케이션이나 API상태를 확인하기에 적합한 HTTP GET 요청을 사용한다.
# 프로브는 5초마다 엔드포인트 /healthz를 호출하여 그 결과를 쿠버네티스에 보고하는데, 응답의 HTTP 상태 코드가 200에서 399 사이면 정상 상태를 보고하고 그 외의 상태 코드는 실패를 보고한다.

<!-- 실습 2 -->
# 수정된 정의를 배치하고, 애플리케이션이 오류를 일으킨 파드가 서비스의 엔드포인트 목록에서 제외되는지 확인하라.

# 예제 12-1의 정의를 배치
kubectl apply -f numbers/update/api-with-readiness.yaml

# 파드가 대체될 때까지 대기
kubectl wait --for=condition=ContainersReady pod -l app=numbers-api,version=v2

# 서비스의 엔드포인트 목록을 확인
kubectl get endpoints numbers-api

# 애플리케이션 컨테이너에 고장을 발생시킴
curl "$(cat api-url.txt)/rng"

# 레디니스 프로브가 동작할 때까지 대기
sleep 10

# 서비스의 엔드포인트 목록을 다시 확인
kubectl get endpoints numbers-api
NAME          ENDPOINTS      AGE
numbers-api   10.1.1.71:80   14m        // 하나가 사라짐!!

# 레디니스 프로브가 파드 중 하나의 등답이 500번을 반환하는 것을 발견한다.
# 그리고 이 파드의 IP 주소가 서비스의 엔드포인트 목록에서 제외된다.
# 그 결과 파드는 더 이상 트래픽을 전달받지 않는다.

# 이 애플리케이션은 다른 수단 없이 레디니스 프로브에만 의존했을 때 생길 수 있는 위험 예이기도 하다.
# 따라서 디플로이먼트는 준비 상태에서 벗어난 파드를 대체하지 않기 때문에 파드는 두개이지만 트래픽을 받는 파드는 하나뿐이다.
# 남은 파드마저 이상을 일으키면 상태가 악화 될 것이다.

<!-- 실습 3 -->
# 현재 서비스 엔드포인트 목록에는 파드가 하나뿐이다.
# 이 파드에 요청을 보내면 이 파드도 고장을 일으켜 두 파드가 모두 서비스에서 제외된다.

# 엔드포인트 확인
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> kubectl get endpoints numbers-api
NAME          ENDPOINTS      AGE
numbers-api   10.1.1.71:80   18m                                                                                        

# 억지로 오류를 일으킨다.
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> curl "$(cat api-url.txt)/rng"                     

# 레디니스 프로브가 실행될 때까지 대기
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> sleep 10

# 엔드포인트 목록 다시 확인
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> kubectl get endpoints numbers-api
NAME          ENDPOINTS   AGE
numbers-api               18m

# 파드의 상태 확인
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch12> kubectl get pods -l app=numbers-api
NAME                           READY   STATUS    RESTARTS   AGE
numbers-api-66cb655595-d6vbl   0/1     Running   0          5m49s                                                       
numbers-api-66cb655595-lzmql   0/1     Running   0          5m45s   

# 이제 두 파드 모두 레디니스 프로브의 상태체크를 통과하지 못하고 서비스의 엔드포인트 목록에서 제외되었다.

# 이쯤 되면 이것이 무슨 자가수복형 애플리케이션인가 싶을 거다.
# 하지만 애플리케이션은 어찌되었든 고장 상태에 있다.
# 레디니스 프로브가 없어도 애플리케이션은 정상 동작하지 않았겠지만, 레디니스 프로브가 있다면 조치하여 다시 요청을 처리할 수 있을 때까지 파드는 트래픽을 받지 않아도 된다.
# 프로브의 상태 체크에 실패한 후 애플리케이션이 스스로 복구할 수 있는지를 알려면 애플리케이션의 실패 모드를 이해해야 된다.

# 쿠버네티스에는 우리 대신 파드를 재시작하는 역할을 할 헬스체크 수단이 하나 더 있다 이를 리브니스 프로브(liveness probe)라고 한다.