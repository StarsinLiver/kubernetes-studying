<!-- 플루언트디와 일래스틱서치를 이용한 중앙화된 로그 관리 -->
# 애플리케이션에서는 대량의 로그가 발생하지만, 이 중 실제로 유용한것은 별로 없다.
# 애플리케이션이 실행되는 파드 수가 급격히 증가하면서 표준적인 쿠버네티스 도구만으로는 로그를 제대로 관리하기 어려워졌다.
# 기업에서는 보통 자체 로그 프레임워크를 사용하는데 이런 로그 프레임워크는 컨테이너에서 발생하는 로그를 수집한후 중앙 저장소에 수집된 로그를 색인, 필터링, 검색하는 수집 후 전달 모델(collect-and-forward model)을 따른다.

<!-- 풀루언트디와 엘라스틱서치가 하는 역할 -->
# 이장은 로그 관리에서 가장 널리 쓰이는 도구인 플루언디(Fluentd)와 일래스틱서치(Elasticsearch)를 활용하여 이런 로그 프레임워크를 구성하는 방법을 다룬다.
# 플루언트디는 컨테이너 로그를 수집하는 역할을 하며, 쿠버네티스와 통합이 쉽다.
# 일래스틱서치는 로그를 저장하는 역할을 하고 클러스터 내에서 파드 형태로 실행되거나 외부 서비스 형태로도 통합될 수 있다.

# 먼저 몇가지 전제사항을 설명하겠다.
# 첫번째는 애플리케이션 로그가 컨테이너 표준 출력 스트림으로 출력되어야 한다는 점이다.
# 그래야 쿠버네티스가 로그를 탐지할 수 있기 때문이다.
# 7장에서 표준 출력 스트림으로 곧바로 로그를 출력하는 경우와 로그 수집용 사이드카 컨테이너를 이용하여 로그를 전달하는 두 가지경우를 살펴보았는데,
# 이 중 후자는 쿠버네티스의 로그 모델이며 도커의 로그 모델과 많은 차이가 있다.

<!-- 쿠버네티스의 로그 관리 -->
# 쿠버네티스의 로그관리는 매우 단순하다. 컨테이너 런타임이 로그를 수집하여 컨테이너를 실행중니 노드에 파일형태로 저장한다.
# 더 복잡한 처리 과정을 원한다면, 별도의 로그 관리 시스템을 배치해야 한다.
# 로그 관리 시스템을 노드에 쌓인 로그를 수집해서 중앙화된 저장소에 전달하고 적절한 UI를 통해 이 로그에 대한 필터링 및 검색 기능을 제공한다.

# 노드는 컨테이너가 출력한 로그를 그대로 저장하는데, 로그 파일이름은 네임스페이스, 파드 , 컨테이너의 이름으로 구성된다.
# 표준 명명 규칙이 있으면 로그 수집기가 로그에 메타데이터를 추가하거나 로그 출처를 식별하는데 도움이 된다.
# 로그 수집기도 파드 형태로 실행되므로, 쿠버네티스 API를 통해 더 자세한 정보를 얻을 수도 있다.
# 플루언트디는 파드의 레이블이나 이미지 태그 정보를 메타데이터에 추가한다.

<!-- 실습 -->
# timecheck 애플리케이션을 또 다른 네임스페이스에 설정을 바꾸어 배치하라, 그리고 kubectl로 로그를 직접 살펴보아라

# timecheck 애플리케이션을 개발 , 테스트 네임스페이스에 배치
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl apply -f .\timecheck\
namespace/kiamol-ch13-dev created
deployment.apps/timecheck created
namespace/kiamol-ch13-test created
configmap/timecheck-config created
deployment.apps/timecheck created

# 개발 네임스페이스의 애플리케이션이 준비될 때까지 대기
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl wait --for=condition=Ready pod -l app=timecheck -n kiamol-ch13-dev
pod/timecheck-7589456574-fhq4z condition met

# 로그를 확인
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-dev --tail 1
2024-01-19 04:56:52.869 +00:00 [INF] Environment: DEV; version: 1.0; time check: 04:56.52

# 테스트 네임스페이스의 애플리케이션이 준비될 때까지 대기
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl wait --for=condition=Ready pod -l app=timecheck -n kiamol-ch13-test
pod/timecheck-76bc55f9c5-7bt49 condition met
pod/timecheck-76bc55f9c5-vgw2k condition met

# 로그를 확인
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl logs -l app=timecheck --all-containers -n kiamol-ch13-test --tail 1
2024-01-19 05:00:30.849 +00:00 [INF] Environment: TEST; version: 1.1; time check: 05:00.30
2024-01-19 05:00:32.851 +00:00 [INF] Environment: TEST; version: 1.1; time check: 05:00.32

# kubectl 1.18부터는 prefix 옵션을 사용하여 이런 정보를 알 수 있지만, 이 옵션도 사용하지않으면 각각의 로그가 어떤 파드에서 출력된 것인지 로그 출처를 확인하기 어렵다.
# 로그를 확인하려면 kubectl을 사용하는 방법이 가장 간단하지만, 결국 로그 파일은 각 노드에 저장되기 때문에 이 파일을 수집만 한다면 다른 방법으로도 로그를 확인할 수 있다.
# 이 장의 예제 코드에는 호스트경로 볼륨으로 로그 파일의 경로를 마운트하는 간단한 sleep 디플로이먼트가 있는데, 이 디플로이먼트로 로그 파일을 직접 확인할 수 있다.

<!-- 실습 2 -->
# 호스트의 로그 파일 디렉터리를 마운트한 파드를 실행하라.

# sleep 디플로이먼트를 배치
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl apply -f .\sleep.yaml
deployment.apps/sleep created

# 파드 컨테이너와 터미널 세션 연결
PS C:\ALL_WORKSPACE\0_GIT\kiamol\ch13> kubectl exec -it deploy/sleep -- sh

# 호스트로그 파일 마운트 경로로 이동
/ # cd /var/log/containers/

# timecheck 애플리케이션의 로그 파일 확인
# 규칙 : 파드이름_네임스페이스_컨테이너이름-컨테이너식별자.log
/var/log/containers # ls timecheck*kiamol-ch13*_logger*
timecheck-7589456574-fhq4z_kiamol-ch13-dev_logger-b1f0c298020614a94a256e9813350f58a0ec2318102d0bae0254f9ee1d5ece35.log
timecheck-76bc55f9c5-7bt49_kiamol-ch13-test_logger-2bb45d3889e3d240d296f09acfae2dd004846162572ec9d69f09b7abd298cfcd.log
timecheck-76bc55f9c5-vgw2k_kiamol-ch13-test_logger-e188caa1bb9ba2c4a70f07d3c2ffd8f0265359a753362b538be8aadeab7bac30.log

# 개발 네임스페이스의 로그 파일 내용 확인
# 로그의 엔트리는 로그 메시지, 타임스탬프, 출력 스트림이 각 필드로 구성된 JSON 포맷으로 되어 있다.
/var/log/containers # cat $(ls timecheck*kiamol-ch13-dev_logger*) | tail -n 1
{"log":"2024-01-19 05:06:02.867 +00:00 [INF] Environment: DEV; version: 1.0; time check: 05:06.02\n","stream":"stdout","time":"2024-01-19T05:06:03.838854826Z"}

# 테미널 세션 종료
/var/log/containers # exit

# 각 컨테이너에는 로그가 출력되는 파일이 있다. timecheck 애플리케이션 컨테이너는 logger라는 사이드카 컨테이너를 경유하여 로그를 출력한다.
# 파일 이름만으로도 로그 출처를 쉽게 알수 있으므로 파일 내용은 컨테이너 런타임에서 출력된 로그를 그대로 담은 JSON 파일이다.

# 로그 파일은 파드가 재시작되더라도 그대로 유지된다. 하지만 대부분의 쿠버네티스 구현체는 노드(쿠버네티스 외부)에 로그 로테이션 기능을 포함하고 있어 로그 파일이 디스크 용량을 모두 차지하는 일을 방지한다.
# 노드에서 로그 파일을 수집하여 중앙 저장소로 전달하면 로그를 한곳에 좀 더 장기적으로 저장할 수 있다.
# 또한 쿠버네티스 DNS 서버, Api 서버, 네트워크 프록시 등 쿠버네티스 코어 컴포넌트에서 생성된 로그도 동일한 방식으로 수집되며 열람할 수 있다.

<!-- 실습 3 -->
# 노드마다 모든 쿠버네티스 코어 컴포넌트가 실행되지는 않지만, SLEEP 파드로 현재 노드에서 실해오디는 공통적인 코어 컴포넌트가 어떤 것이 있는지 확인할 수 있다.

# sleep 파드에 터미널 세션 연결
kubectl exec -it deploy/sleep -- sh

# 호스트경로 볼륨의 마운트 경로로 이동
cd /var/log/containers/

# 네트워크 프록시는 모드 노드에서 실행된다.
/var/log/containers # cat $(ls kube-proxy*) | tail -n 1
{"log":"I0119 03:42:55.173682       1 shared_informer.go:318] Caches are synced for service config\n","stream":"stderr","time":"2024-01-19T03:42:55.180389957Z"}

# 현재 노드에서 코어 DNS를 사용중이라면 로그를 볼 수 있다.
/var/log/containers # cat $(ls coredns*) | tail -n 1
{"log":"[INFO] plugin/ready: Still waiting on: \"kubernetes\"\n","stream":"stdout","time":"2024-01-19T03:43:00.3619788Z"}

# 현재 노드에서 API 서버가 실행중이라면 로그를 볼 수 있다.
/var/log/containers # cat $(ls kube-apiserver*) | tail -n 1
{"log":"W0119 05:16:28.078396       1 watcher.go:245] watch chan error: etcdserver: mvcc: required revision has been compacted\n","stream":"stderr","time":"2024-01-19T05:16:28.078630091Z"}

# 터미널 세션 종료
/var/log/containers # exit

# 네트워크 프록시 파드는 노드마다 하나씩 실행되므로 클러스터 구성과 상관없이 볼 수 있다.
# 하지만 DNS 로그는 여러분 클러스터 구성에 기본 DNS 플로그인(CoreDNS)가 사용되지 않았다면 볼 수 없고, Api 서버 로그는 해당 노드에서 API를 실행 중이어야만 볼 수 있다.

# 지금까지 쿠버네티스에서 컨테이너 로그를 처리하고 저장하는 과정을 알아보았다.